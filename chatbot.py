import os
from dotenv import load_dotenv
import log
import sys

from langchain_openai import ChatOpenAI
from langchain_core.prompts import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate
)

from langchain_core.output_parsers import StrOutputParser
from langchain_core.callbacks import StreamingStdOutCallbackHandler

# API KEY ì •ë³´ë¡œë“œ
load_dotenv()

log.langsmith('First Chagbot')

# 1. System prompt (ì—­í•  ì§€ì •)
system_prompt = SystemMessagePromptTemplate.from_template(
    "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì§€ì‹ì´ í’ë¶€í•œ í•œêµ­ì–´ AI ì±—ë´‡ì…ë‹ˆë‹¤. í•­ìƒ ì •ì¤‘í•˜ê³  ìƒì„¸í•˜ê²Œ ëŒ€ë‹µí•˜ì„¸ìš”."
)

# 2. User prompt ì„¤ì •

user_prompt = HumanMessagePromptTemplate.from_template("{user_input}")

# 3. CahtPromptTemplateìœ¼ë¡œ ê²°í•©
chat_prompt = ChatPromptTemplate.from_messages([system_prompt, user_prompt])

# 4. Streaming ê°€ëŠ¥í•œ LLM êµ¬ì„±
model = ChatOpenAI(
    model= 'gpt-4-turbo',
    temperature= 0.7,
    max_tokens=256,
    streaming=True,
    callbacks=[StreamingStdOutCallbackHandler()]
)

# 5. Output Parser
parser = StrOutputParser()

# 6. ì „ì²´ ì²´ì¸ êµ¬ì„±
chain = chat_prompt | model | parser

# Method
def run_chatbot():
    print("ğŸ¥”ğŸ¥”ğŸ¥” ë§í•˜ëŠ” ê°ìì˜ ìŠ¤íŠ¸ë¦¬ë° ì±—ë´‡ì— ì˜¤ì‹  ê±¸ í™˜ì˜í•©ë‹ˆë‹¤! (ì¢…ë£Œ: exit)ğŸ¥”ğŸ¥”ğŸ¥”")
    while True:
        print("\nğŸ‘¤ User: ", end="", flush=True)
        try:
            user_input = sys.stdin.readline().strip()
        except UnicodeDecodeError:
            print("âŒ ì…ë ¥ ì¸ì½”ë”© ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            continue

        print("ğŸ¤– ì±—ë´‡: ", end="", flush=True)
        try:
            _ = chain.invoke({"user_input": user_input})
            print("")  # ì¤„ë°”ê¿ˆ
        except Exception as e:
            print(f"\nâš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == '__main__':
    run_chatbot()